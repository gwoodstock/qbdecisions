{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "# data: https://www.kaggle.com/c/nfl-big-data-bowl-2021/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_paths(path='./nfl-big-data-bowl-2021/weeks/'):\n",
    "    \"\"\"get file paths of all raw nfl game data split by week\"\"\"\n",
    "    \n",
    "    return sorted(['.' + os.sep + os.path.relpath(path) + os.sep + p for p in os.listdir(path) if not p.startswith('.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_team(x):\n",
    "    \"\"\"Get the home/away team abbrev for a given play via apply from home_away data dict. Level 1\"\"\"\n",
    "    \n",
    "    g_id = x['gameId']\n",
    "    t_id = home_away[g_id]  # 0 for home, 1 for away\n",
    "    if x['team'] == 'home':\n",
    "        return t_id[0]\n",
    "    if x['team'] == 'away':\n",
    "        return t_id[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_possession(x):\n",
    "    \"\"\"Get the possession for a given play via apply from possession data dict. Level 1\"\"\"\n",
    "    possession = off_def.get(x['gameId'])\n",
    "    possession = possession.get(x['playId'])\n",
    "    return possession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ball_loc(x):\n",
    "    \"\"\"Get the ball specs for a given play via apply from ball_specs data dict. Level 1\"\"\"\n",
    "    gameId = x['gameId']\n",
    "    playId = x['playId']\n",
    "    frameId = x['frameId']\n",
    "    vals = ball_specs[gameId][playId].get(frameId, (0, 0, 0, 0, 0))\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_x_play_right(x):\n",
    "    \"\"\"Invert x coord of plays with direction = 'right'. Level 1\"\"\"\n",
    "    if x['playDirection'] == 'right':\n",
    "        return 120 - x['x']\n",
    "    else:\n",
    "        return x['x']\n",
    "\n",
    "def invert_y_play_right(x):\n",
    "    \"\"\"Invert y coord of plays with direction = 'right'. Level 1\"\"\"\n",
    "    if x['playDirection'] == 'right':\n",
    "        return 53.3 - x['y']\n",
    "    else:\n",
    "        return x['y']\n",
    "\n",
    "def invert_o_play_right(x):\n",
    "    \"\"\"Invert o metric of plays with direction = 'right'. Level 1\"\"\"\n",
    "\n",
    "    if x['playDirection'] == 'right':\n",
    "        return 360 - x['o']\n",
    "    else:\n",
    "        return x['o']\n",
    "\n",
    "def invert_dir_play_right(x):\n",
    "    \"\"\"Invert dir metric of plays with direction = 'right'. Level 1\"\"\"\n",
    "\n",
    "    if x['playDirection'] == 'right':\n",
    "        return 360 - x['dir']\n",
    "    else:\n",
    "        return x['dir']\n",
    "\n",
    "def invert_ball_x_play_right(x):\n",
    "    \"\"\"Invert x coord of ball for plays with direction = 'right'. Level 1\"\"\"\n",
    "    if x['playDirection'] == 'right':\n",
    "        return 120 - x['ball_x']\n",
    "    else:\n",
    "        return x['ball_x']\n",
    "\n",
    "def invert_ball_y_play_right(x):\n",
    "    \"\"\"Invert y coord of ball for plays with direction = 'right'. Level 1\"\"\"\n",
    "    if x['playDirection'] == 'right':\n",
    "        return 53.3 - x['ball_y']\n",
    "    else:\n",
    "        return x['ball_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(x1, y1, x2, y2):\n",
    "    dist = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    return dist\n",
    "\n",
    "calc_distances = np.vectorize(get_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_to_ball(x):\n",
    "    \"\"\"Calculate given player's distance to the ball. Level 2\"\"\"\n",
    "    # player\n",
    "    x1 = x['x']\n",
    "    y1 = x['y']\n",
    "\n",
    "    # ball\n",
    "    x2 = x['ball_x']\n",
    "    y2 = x['ball_y']\n",
    "\n",
    "    dist = get_dist(x1, y1, x2, y2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_week_data(start=1, stop=17, level=0):\n",
    "    paths = file_paths()                                                                                        # paths of all .csv files\n",
    "    weeks = list(range(start, (stop+1)))                                                                        # convert week range to list\n",
    "\n",
    "    if level == 0:\n",
    "        for week in weeks:                                                                                          # iterate over lists\n",
    "            if any([(f'week{str(week)}.csv') in p for p in paths]):                                                 # check if file path exists for week\n",
    "\n",
    "                data = pd.read_csv(file_paths()[np.array([(f'week{str(week)}.csv') in p for p in paths]).argmax()]) # get index location from list containing all file paths of specified week\n",
    "                data['week'] = week                                                                                 # assign week column to output \n",
    "                yield data                                                                                          # return data for given week\n",
    "    else:\n",
    "        for week in weeks:\n",
    "            path=f'./data/level_{level}/l{level}_week_{week}.csv'\n",
    "            data = pd.read_csv(path, compression='zip')\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ball locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/stores/ball_specs.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    ball_specs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game location dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/stores/home_away.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    home_away = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possession dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/stores/possession.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    off_def = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targeted on play dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/stores/targeted.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    targeted = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/stores/pass_complete.pkl'\n",
    "with open(path, 'rb') as f:\n",
    "    pass_complete = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolating only the rows necessary for making predictions on the web portal. No predictions can be made before the ball is snapped or after the pass is thrown. The goal is to predict every frame for every eligable receiver on the field between these two points in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snap_to_pass(play_data):\n",
    "    play_data.reset_index(drop=True, inplace=True)\n",
    "    pass_data = pd.DataFrame(data=[], columns=play_data.columns)\n",
    "    \n",
    "    if 'pass_forward' in play_data['event'].unique() and any(play_data['event'].str.startswith('pass_outcome')):\n",
    "        # get frameId where pass originates\n",
    "        start = play_data[play_data['event'] == 'ball_snap']['frameId'].idxmin()\n",
    "        start = play_data.loc[start, 'frameId']\n",
    "        # get frameId where pass outcome occurs\n",
    "        stop = play_data[play_data['event'].str.startswith('pass_outcome')]['frameId'].idxmin()\n",
    "        stop = play_data.loc[stop, 'frameId']\n",
    "        # filter pass data\n",
    "        pass_data = play_data[(play_data['frameId'] >= start) & (play_data['frameId'] <= stop)]\n",
    "        pass_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    return pass_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 1 complete\n",
      "Week 2 complete\n",
      "Week 3 complete\n",
      "Week 4 complete\n",
      "Week 5 complete\n",
      "Week 6 complete\n",
      "Week 7 complete\n",
      "Week 8 complete\n",
      "Week 9 complete\n",
      "Week 10 complete\n",
      "Week 11 complete\n",
      "Week 12 complete\n",
      "Week 13 complete\n",
      "Week 14 complete\n",
      "Week 15 complete\n",
      "Week 16 complete\n",
      "Week 17 complete\n"
     ]
    }
   ],
   "source": [
    "weeks = gen_week_data(level=2)\n",
    "\n",
    "for week in weeks:\n",
    "    passes = pd.DataFrame()\n",
    "    w = week['week'].iloc[0]\n",
    "    games = week['gameId'].unique()\n",
    "    for game in games:\n",
    "        plays = week[week['gameId'] == game]['playId'].unique()\n",
    "        for play in plays:\n",
    "            play = week[(week['gameId'] == game) & (week['playId'] == play)]\n",
    "            \n",
    "            if 'pass_forward' in play['event'].unique() and 'pass_tipped' not in play['event'].unique():\n",
    "                play = snap_to_pass(play)\n",
    "                passes = pd.concat([passes, play], ignore_index=True)\n",
    "                \n",
    "    passes.to_csv(f'./data/subset/web/week_{w}_passes.csv', compression='zip', index=False)\n",
    "    print(f'Week {w} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing all 17 weeks will take an exceptionally long time. Will spin up a few google colab notebooks and parallel process 5 at a time. With 17 iterations of the following code block processing time will be significantly reduced. Will then save the processed .csv files to my local HD for the final processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting week 14\n",
      "Week 14 - Game 1/16 completed\n",
      "Week 14 - Game 2/16 completed\n",
      "Week 14 - Game 3/16 completed\n",
      "Week 14 - Game 4/16 completed\n",
      "Week 14 - Game 5/16 completed\n",
      "Week 14 - Game 6/16 completed\n",
      "Week 14 - Game 7/16 completed\n",
      "Week 14 - Game 8/16 completed\n",
      "Week 14 - Game 9/16 completed\n",
      "Week 14 - Game 10/16 completed\n",
      "Week 14 - Game 11/16 completed\n",
      "Week 14 - Game 12/16 completed\n",
      "Week 14 - Game 13/16 completed\n",
      "Week 14 - Game 14/16 completed\n",
      "Week 14 - Game 15/16 completed\n",
      "Week 14 - Game 16/16 completed\n",
      "Starting week 15\n",
      "Week 15 - Game 1/16 completed\n",
      "Week 15 - Game 2/16 completed\n",
      "Week 15 - Game 3/16 completed\n",
      "Week 15 - Game 4/16 completed\n",
      "Week 15 - Game 5/16 completed\n",
      "Week 15 - Game 6/16 completed\n",
      "Week 15 - Game 7/16 completed\n",
      "Week 15 - Game 8/16 completed\n",
      "Week 15 - Game 9/16 completed\n",
      "Week 15 - Game 10/16 completed\n",
      "Week 15 - Game 11/16 completed\n",
      "Week 15 - Game 12/16 completed\n",
      "Week 15 - Game 13/16 completed\n",
      "Week 15 - Game 14/16 completed\n",
      "Week 15 - Game 15/16 completed\n",
      "Week 15 - Game 16/16 completed\n",
      "Starting week 16\n",
      "Week 16 - Game 1/16 completed\n",
      "Week 16 - Game 2/16 completed\n",
      "Week 16 - Game 3/16 completed\n",
      "Week 16 - Game 4/16 completed\n",
      "Week 16 - Game 5/16 completed\n",
      "Week 16 - Game 6/16 completed\n",
      "Week 16 - Game 7/16 completed\n",
      "Week 16 - Game 8/16 completed\n",
      "Week 16 - Game 9/16 completed\n",
      "Week 16 - Game 10/16 completed\n",
      "Week 16 - Game 11/16 completed\n",
      "Week 16 - Game 12/16 completed\n",
      "Week 16 - Game 13/16 completed\n",
      "Week 16 - Game 14/16 completed\n",
      "Week 16 - Game 15/16 completed\n",
      "Week 16 - Game 16/16 completed\n",
      "Starting week 17\n",
      "Week 17 - Game 1/16 completed\n",
      "Week 17 - Game 2/16 completed\n",
      "Week 17 - Game 3/16 completed\n",
      "Week 17 - Game 4/16 completed\n",
      "Week 17 - Game 5/16 completed\n",
      "Week 17 - Game 6/16 completed\n",
      "Week 17 - Game 7/16 completed\n",
      "Week 17 - Game 8/16 completed\n",
      "Week 17 - Game 9/16 completed\n",
      "Week 17 - Game 10/16 completed\n",
      "Week 17 - Game 11/16 completed\n",
      "Week 17 - Game 12/16 completed\n",
      "Week 17 - Game 13/16 completed\n",
      "Week 17 - Game 14/16 completed\n",
      "Week 17 - Game 15/16 completed\n",
      "Week 17 - Game 16/16 completed\n"
     ]
    }
   ],
   "source": [
    "for w in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]:\n",
    "    output = pd.DataFrame()\n",
    "    week = pd.read_csv(f'./data/subset/web/week_{w}_passes.csv', compression='zip')\n",
    "    i = week['week'].iloc[0]\n",
    "    print(f'Starting week {i}')\n",
    "\n",
    "    games = week['gameId'].unique()\n",
    "    g = 0\n",
    "\n",
    "    for game in games:\n",
    "        g += 1\n",
    "        plays = week[week['gameId'] == game]['playId'].unique()\n",
    "\n",
    "        for play in plays:\n",
    "            frames = week[(week['gameId'] == game) & (week['playId'] == play)]['frameId'].unique()\n",
    "\n",
    "            for frame in frames:\n",
    "                \n",
    "                df = week[(week['gameId'] == game) & (week['playId'] == play) & (week['frameId'] == frame)].copy()\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                football = df[df['displayName'] == 'Football']\n",
    "                football.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                p_0 = df.loc[(df['possession'] == 0) & (df['displayName'] != 'Football'),:].copy()\n",
    "                p_0.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                p_1 = df.loc[(df['possession'] == 1) & (df['displayName'] != 'Football'),:].copy()\n",
    "                p_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                if p_0.shape[0] > 0 and p_1.shape[0] > 0:\n",
    "                    # Calculate offenses distance to defenders\n",
    "                    closest_to_def = []\n",
    "                    for def_player in range(p_0.shape[0]):\n",
    "                        \n",
    "                        loc_x = p_0.iloc[def_player]['x']\n",
    "                        loc_y = p_0.iloc[def_player]['y']\n",
    "\n",
    "                        opp_loc_x = p_1['x']\n",
    "                        opp_loc_y = p_1['y']\n",
    "\n",
    "                        dist_vect = calc_distances(\n",
    "                            np.full_like(opp_loc_x, loc_x),\n",
    "                            np.full_like(opp_loc_y, loc_y),\n",
    "                            opp_loc_x,\n",
    "                            opp_loc_y\n",
    "                        )\n",
    "                        closest_idx = dist_vect.argmin()\n",
    "                        closest_dist = dist_vect[closest_idx]\n",
    "\n",
    "                        closest_stats = p_1.loc[closest_idx, ['s', 'o', 'a', 'dis', 'dir']]\n",
    "                        closest_stats['dist'] = closest_dist\n",
    "                        \n",
    "                        closest_to_def.append(closest_stats.to_list())\n",
    "                        \n",
    "                    def_oppo_stats = pd.DataFrame(closest_to_def, columns=closest_stats.index).add_prefix('opp_')\n",
    "                    def_oppo_stats = pd.concat([p_0[['gameId', 'playId', 'frameId', 'displayName']], def_oppo_stats], axis=1)\n",
    "\n",
    "                    # Calculate defenders distance to offense\n",
    "                    closest_to_off = []\n",
    "                    for off_player in range(p_1.shape[0]):\n",
    "                        \n",
    "                        loc_x = p_1.iloc[off_player]['x']\n",
    "                        loc_y = p_1.iloc[off_player]['y']\n",
    "\n",
    "                        opp_loc_x = p_0['x']\n",
    "                        opp_loc_y = p_0['y']\n",
    "\n",
    "                        dist_vect = calc_distances(\n",
    "                            np.full_like(opp_loc_x, loc_x),\n",
    "                            np.full_like(opp_loc_y, loc_y),\n",
    "                            opp_loc_x,\n",
    "                            opp_loc_y\n",
    "                        )\n",
    "\n",
    "                        closest_idx = dist_vect.argmin()\n",
    "                        closest_dist = dist_vect[closest_idx]\n",
    "\n",
    "                        closest_stats = p_0.loc[closest_idx, ['s', 'o', 'a', 'dis', 'dir']]\n",
    "                        closest_stats['dist'] = closest_dist\n",
    "                        \n",
    "                        closest_to_off.append(closest_stats.to_list())\n",
    "                        \n",
    "                    off_oppo_stats = pd.DataFrame(closest_to_off, columns=closest_stats.index).add_prefix('opp_')\n",
    "                    off_oppo_stats = pd.concat([p_1[['gameId', 'playId', 'frameId', 'displayName']], off_oppo_stats], axis=1)\n",
    "\n",
    "                    # merge all\n",
    "                    football = pd.DataFrame([[game, play, frame, 'Football', 0, 0, 0, 0, 0, 0]], columns=off_oppo_stats.columns)\n",
    "                    both_teams = pd.concat([def_oppo_stats, off_oppo_stats, football], ignore_index=True)\n",
    "\n",
    "                    output = pd.concat([output, both_teams], ignore_index=True)\n",
    "        print(f'Week {w} - Game {g}/{len(games)} completed')  \n",
    "\n",
    "    output.to_csv(f'./data/subset/web/processed_week_{w}_passes.csv', index=False, compression='zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the nearest opponent locations with the original row. Data will be read for modeling after dealing with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 1 complete\n",
      "Week 2 complete\n",
      "Week 3 complete\n",
      "Week 4 complete\n",
      "Week 5 complete\n",
      "Week 6 complete\n",
      "Week 7 complete\n",
      "Week 8 complete\n",
      "Week 9 complete\n",
      "Week 10 complete\n",
      "Week 11 complete\n",
      "Week 12 complete\n",
      "Week 13 complete\n",
      "Week 14 complete\n",
      "Week 15 complete\n",
      "Week 16 complete\n",
      "Week 17 complete\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 18):\n",
    "\n",
    "    week = pd.read_csv(f'./data/subset/web/week_{n}_passes.csv', compression='zip')\n",
    "    week.reset_index(drop=True, inplace=True)\n",
    "    games = week['gameId'].unique()\n",
    "\n",
    "    week['pass_complete'] = 0\n",
    "\n",
    "\n",
    "    for game in games:\n",
    "        plays = week[week['gameId'] == game]['playId'].unique()\n",
    "\n",
    "        for play in plays:\n",
    "            completion = pass_complete[game][play]['pass']\n",
    "            if completion:\n",
    "                completion = 1\n",
    "            else:\n",
    "                completion = 0\n",
    "            \n",
    "            compl_shape = week.loc[(week['gameId'] == game) & (week['playId'] == play)]['pass_complete']\n",
    "\n",
    "            week.loc[(week['gameId'] == game) & (week['playId'] == play), 'pass_complete'] = np.full_like(compl_shape, completion)\n",
    "    \n",
    "    opponents = pd.read_csv(f'./data/subset/web/processed_week_{n}_passes.csv', compression='zip')\n",
    "\n",
    "    output = pd.merge(left=opponents, right=week, left_on=['gameId', 'playId', 'frameId', 'displayName'], right_on=['gameId', 'playId', 'frameId', 'displayName'], how='inner')\n",
    "\n",
    "    output.to_csv(f'./data/subset/web/week_{n}.csv', index=False, compression='zip')\n",
    "    w = week['week'].iloc[0]\n",
    "    print(f'Week {w} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A larger subset of data is now cleaned and ready to be predicted by the model. These predictions will be for the catch percentage. The catch percentage will then multiplied by the estimated expected points added. With estimated expected points added * catch percentage a prediction for the \"optimal\" receiver can be made. \n",
    "\n",
    "For example,\n",
    "\n",
    "Lets say two receivers are both 10 yards down the field. Both with an estimated expected points added (EPA) of +1.0 points. Receiver A has an estimated catch percentage of 65%. Receiver B has an estimated catch percentage of 35%. The adjusted estimated EPA for Receiver A will be 0.65 points because he has a 65% chance of increasing the expected points of the given drive by 1 point. Reciver B will have an adjusted estimated EPA of +0.35 points. Therefore, Receiver A will be the \"optimal receiver\" for the given play."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6aaf12f00e2accd7ab3a69f0361120d5b81b11b109d190d2913220c8ee37ccf8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
